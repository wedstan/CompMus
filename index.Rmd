---
title: "Make the World Dance"
output: 
  flexdashboard::flex_dashboard:
    orientation: columns
    vertical_layout: fill
    storyboard: true
    theme: 
      version: 4
      bootswatch: minty
---

```{r setup, include=FALSE}
library(flexdashboard)
library(tidyverse)
library(tidymodels)
library(ggdendro)
library(heatmaply)
library(plotly)
library(shiny)
library(jsonlite) 
library(readr)
library(ggplot2)
library(tidyverse)
source("compmus.R")
compmus2025 <- read_csv("compmus2025.csv")
#      C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B
major_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <-
  c(   1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <-
  c(   1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)

major_key <-
  c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
  c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)

chord_templates <-
  tribble(
    ~name, ~template,
    "Gb:7", circshift(seventh_chord, 6),
    "Gb:maj", circshift(major_chord, 6),
    "Bb:min", circshift(minor_chord, 10),
    "Db:maj", circshift(major_chord, 1),
    "F:min", circshift(minor_chord, 5),
    "Ab:7", circshift(seventh_chord, 8),
    "Ab:maj", circshift(major_chord, 8),
    "C:min", circshift(minor_chord, 0),
    "Eb:7", circshift(seventh_chord, 3),
    "Eb:maj", circshift(major_chord, 3),
    "G:min", circshift(minor_chord, 7),
    "Bb:7", circshift(seventh_chord, 10),
    "Bb:maj", circshift(major_chord, 10),
    "D:min", circshift(minor_chord, 2),
    "F:7", circshift(seventh_chord, 5),
    "F:maj", circshift(major_chord, 5),
    "A:min", circshift(minor_chord, 9),
    "C:7", circshift(seventh_chord, 0),
    "C:maj", circshift(major_chord, 0),
    "E:min", circshift(minor_chord, 4),
    "G:7", circshift(seventh_chord, 7),
    "G:maj", circshift(major_chord, 7),
    "B:min", circshift(minor_chord, 11),
    "D:7", circshift(seventh_chord, 2),
    "D:maj", circshift(major_chord, 2),
    "F#:min", circshift(minor_chord, 6),
    "A:7", circshift(seventh_chord, 9),
    "A:maj", circshift(major_chord, 9),
    "C#:min", circshift(minor_chord, 1),
    "E:7", circshift(seventh_chord, 4),
    "E:maj", circshift(major_chord, 4),
    "G#:min", circshift(minor_chord, 8),
    "B:7", circshift(seventh_chord, 11),
    "B:maj", circshift(major_chord, 11),
    "D#:min", circshift(minor_chord, 3)
  )

key_templates <-
  tribble(
    ~name, ~template,
    "Gb:maj", circshift(major_key, 6),
    "Bb:min", circshift(minor_key, 10),
    "Db:maj", circshift(major_key, 1),
    "F:min", circshift(minor_key, 5),
    "Ab:maj", circshift(major_key, 8),
    "C:min", circshift(minor_key, 0),
    "Eb:maj", circshift(major_key, 3),
    "G:min", circshift(minor_key, 7),
    "Bb:maj", circshift(major_key, 10),
    "D:min", circshift(minor_key, 2),
    "F:maj", circshift(major_key, 5),
    "A:min", circshift(minor_key, 9),
    "C:maj", circshift(major_key, 0),
    "E:min", circshift(minor_key, 4),
    "G:maj", circshift(major_key, 7),
    "B:min", circshift(minor_key, 11),
    "D:maj", circshift(major_key, 2),
    "F#:min", circshift(minor_key, 6),
    "A:maj", circshift(major_key, 9),
    "C#:min", circshift(minor_key, 1),
    "E:maj", circshift(major_key, 4),
    "G#:min", circshift(minor_key, 8),
    "B:maj", circshift(major_key, 11),
    "D#:min", circshift(minor_key, 3)
  )
get_conf_mat <- function(fit) {
  outcome <- .get_tune_outcome_names(fit)
  fit |> 
    collect_predictions() |> 
    conf_mat(truth = outcome, estimate = .pred_class)
}  

get_pr <- function(fit) {
  fit |> 
    conf_mat_resampled() |> 
    group_by(Prediction) |> mutate(precision = Freq / sum(Freq)) |> 
    group_by(Truth) |> mutate(recall = Freq / sum(Freq)) |> 
    ungroup() |> filter(Prediction == Truth) |> 
    select(class = Prediction, precision, recall)
}  
cluster_juice <-
  recipe(
    filename ~
      arousal +
      danceability +
      instrumentalness +
      tempo +
      valence,
    data = compmus2025
  ) |>
  step_center(all_predictors()) |>
  step_scale(all_predictors()) |> 
  # step_range(all_predictors()) |> 
  prep(compmus2025) |>
  juice() |>
  column_to_rownames("filename")
compmus_dist <- dist(cluster_juice, method = "euclidean")
```

# Introduction {.tabset}

### Origin of My Selected Tracks. I sourced my tracks from this AI Styles Library—a surprisingly expressive and diverse set of tracks generated by an AI trained in music composition. This made it the perfect starting point to explore what makes music danceable. {.column .center data-width="10%"}

```{r}
valueBox("AIVA’s Styles Library")
```

### I was particularly drawn to their groove, rhythmic patterns and danceable energy. The uplifting beats and engaging melodies create an inspiring and refreshing listening experience. \n Curious whether there is a pattern or template that can be extracted. Specifically, a structured approach that could transform a calm or melancholic piece of music into an exciting, dance-inducing track. {.column .center data-width="50%"}

::: {style="text-align: center;"}
<p style="font-size: 18px; max-width: 80%; margin: auto;">

</p>
:::

```{r}
valueBox("Why These?")
```

### Top vs Bottom Danceability Heatmap Analysis{.column .center data-width="90%"}

```{r}
compmus_dist |> 
  hclust(method = "single") |> # Try single, average, and complete.
  dendro_data() |>
  ggdendrogram()
top5 <- cluster_juice |> arrange(desc(danceability)) |> head(5)
bottom5 <- cluster_juice |> arrange(danceability) |> head(5)

# 画图
top_plot <- heatmaply(top5,
          main = "Top 5",
          dist_method = "euclidean",
          hclust_method = "average")

bottom_plot <- heatmaply(bottom5,
          main = "Bottom 5",
          dist_method = "euclidean",
          hclust_method = "average")
subplot(top_plot, bottom_plot, titleX = TRUE, titleY = TRUE)%>%
  layout(
    title = list(
      text = "Top vs Bottom 5 Danceability Tracks",
      x = 0.5,
      y = 1.1,         # 推高位置避免和图重叠
      xanchor = "center"
    )
  )
```

> Using a heatmap, I compared the top 5 most danceable tracks and the bottom 5 least danceable ones to identify distinguishing features.
Surprisingly, I found that higher danceability was more associated with high arousal and valence, but not necessarily with higher tempo.
In contrast, the least danceable tracks tended to have very high instrumentalness and tempo, but scored low on emotional expressiveness (low valence and arousal).
This challenges the common assumption that faster music is always more danceable. Instead, emotional intensity and presence of vocals might matter more.
Because this finding was counter-intuitive, I wanted to further explore why some tracks feel more danceable even if they’re slower, so I shifted from corpus-level to track-level analysis.

# 1st Attempt at Explaining Danceability--Corpus-level comparison

## Column {.tabset}

### Hypothesis 1: Tempo → Danceability

```{r}
aisc2024 <- compmus2025 |> 
  mutate(
    highest =	filename %in% c("roemer-i-1", "roemer-i-2"),
    is_mine = filename %in% c("wednesday-w-1", "wednesday-w-2"),
    label = case_when(
      is_mine ~ filename,
      highest ~ "roemer-i-2",   # 只给 roemer-i-2 加标签
      TRUE ~ NA_character_
    )
  )

# 画图
ggplot(
  aisc2024,
  aes(
    x = tempo,
    y = danceability,
    colour = is_mine | highest
  )
) +
  geom_point(alpha = 0.6) +
  geom_text(aes(label = label), hjust = -0.1, vjust = 0.3, size = 3, na.rm = TRUE) +
  scale_color_manual(
    values = c("FALSE" = "grey80", "TRUE" = "darkgreen"),
    labels = c("Other Tracks", "Selected Tracks"),
    name = "Track Type"
  ) +
  scale_x_continuous(
    limits = c(50, 200),
    breaks = c(50, 100, 150, 180),
    minor_breaks = NULL
  ) +
  scale_y_continuous(
    limits = c(0, 1),
    minor_breaks = NULL
  ) +
  scale_size_continuous(trans = "exp", guide = "none") +
  theme_light() +
  labs(
    title = "Where My Tracks Sit in the Danceability Space",
    x = "Tempo (BPM)",
    y = "Danceability",
    colour = "Track Type"
  )
```

> **Thinking:**<br><br> Compared to the full dataset, my selected tracks (wednesday-w-1 and wednesday-w-2) exhibit above-average danceability, indicating a strong groove and rhythmic presence.
However, they are not the most danceable—that distinction belongs to roemer-i-2, which sits at the top of the chart.
Interestingly, although my tracks have a higher tempo, they are still outperformed in danceability. This suggests that tempo alone does not determine how danceable a track feels. There might be other influential features at play, such as engagingness, valence, or instrumental texture. <br><br>

### Hypothesis 2: Arousal → Danceability

```{r}
ggplot(compmus2025, aes(x = arousal, y = danceability)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  geom_smooth(method = "lm", se = TRUE, color = "red", linetype = "dashed") +
  labs(
    title = "Relationship between Arousal and Danceability",
    x = "Arousal",
    y = "Danceability"
  ) +
  theme_minimal()
```

> **Thinking:** <br><br> While tempo and approachability showed little or no relationship to danceability, arousal appears to have a weak-to-moderate positive correlation with it.
The plot shows a general upward trend, indicating that more energetic or intense tracks tend to be slightly more danceable.
However, the correlation is not particularly strong—many low-arousal tracks still have high danceability, and vice versa.
This suggests that while energy might help, it is not the sole or strongest factor in determining how danceable a track is.

### Hypothesis 3: Approachability → Danceability

```{r}
ggplot(compmus2025, aes(x = approachability, y = danceability)) +
  geom_point(alpha = 0.6, color = "steelblue") +
  geom_smooth(method = "lm", se = TRUE, color = "red", linetype = "dashed") +
  labs(
    title = "Relationship between Approachability and Danceability",
    x = "Approachability",
    y = "Danceability"
  ) +
  theme_minimal()
```

> **Thinking:** <br><br> Although it might seem intuitive that more approachable tracks are also more danceable, this plot reveals no clear linear relationship between the two features.
Songs with similar approachability scores exhibit a wide range of danceability values, suggesting that danceability is not primarily driven by affective features like approachability.
Taken together with the previous hypotheses involving tempo and arousal, this finding leads to a broader conclusion:
Track-level descriptors alone may not sufficiently explain why a piece of music feels danceable.
Instead, as discussed in music structure analysis (Chapter 4), danceability may emerge from deeper mid-level features, such as:
Chroma-based features, which capture harmonic and melodic repetition,
MFCC-based features, which reflect timbral contrast,
and tempograms, which encode rhythmic energy over time.
In short, danceability is not simply a sum of isolated attributes, but a result of how musical elements interact temporally and structurally — across sections, grooves, and repetitions.
Therefore, I decided to shift my focus from the entire corpus to a deeper structural analysis of my own selected track.
By visualizing features such as chromagrams and MFCCs over time, I aim to uncover whether my track contains structural signatures that contribute to its danceability.

# 2nd Attempt: Track-Level Analysis

Column{.tabset}
--------

### Track 1: Chromagram 

```{r}
"features/wednesday-w-1.json" |>                           # Change the track
  compmus_chroma(norm = "identity") |>                 
  # Change the norm
  ggplot(aes(x = time, y = pc, fill = value)) + 
  geom_raster() +
  scale_y_continuous(
    breaks = 0:11,
    minor_breaks = NULL,
    labels = c(
                "C", "C#|Db", "D", "D#|Eb",
                "E", "F", "F#|Gb", "G",
                "G#|Ab", "A", "A#|Bb", "B"
              )
  ) +
  scale_fill_viridis_c(option = "G") +               
  # Change the colours?
  labs(x = "Time (s)", y = NULL, fill = NULL) +
  theme_classic()  
```

> This track exhibits clear harmonic repetition, with strong vertical striping indicating repeated pitch patterns.
This kind of structure is closely related to groove and may contribute to its danceability.

### Cepstrogram 

```{r}
"features/wednesday-w-1.json" |>                           #Change the track
  compmus_mfccs(norm = "identity") |>                  #Change the norm
  ggplot(aes(x = time, y = mfcc, fill = value)) + 
  geom_raster() +
  scale_y_continuous(
    breaks = 0:12,
    minor_breaks = NULL,
  ) +
  scale_fill_viridis_c(guide = "none") +               #Change the colours?
  labs(x = "Time (s)", y = "Coefficient Number", fill = NULL) +
  theme_classic()                                      
```

> Track 1 shows stable timbral energy concentrated in lower MFCC coefficients, suggesting a consistent and smooth sonic texture that supports groove.

### Chroma-based

```{r}
"features/wednesday-w-1.json" |>                           # Change the track
  compmus_chroma(norm = "identity") |>                 # Change the norm
  compmus_self_similarity(
    feature = pc,
    distance = "euclidean"                             # Change the distance
  ) |>   
  ggplot(aes(x = xtime, y = ytime, fill = d)) + 
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +               # Change the colours?
  labs(x = "Time (s)", y = NULL, fill = NULL) +
  theme_classic() 
```

> Track 1 reveals a highly regular harmonic structure, as shown by the dense and symmetrical grid-like patterns in its chroma-based self-similarity matrix. This indicates strong harmonic repetition—such as loops or consistent chord progressions—which may support the feeling of groove and enhance danceability.

### Timbre-based

```{r}
"features/wednesday-w-1.json" |>                           # Change the track
  compmus_mfccs(norm = "identity") |>                  # Change the norm
  compmus_self_similarity(
    feature = mfcc,
    distance = "euclidean"                             # Change the distance
  ) |>   
  ggplot(aes(x = xtime, y = ytime, fill = d)) + 
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +               # Change the colours?
  labs(x = "Time (s)", y = NULL, fill = NULL) +
  theme_classic() 
```

> Track 1 shows clear sectional structure in its timbre-based self-similarity matrix, with large, cohesive blocks indicating repeated segments. These repeating timbral sections likely reflect a structured form (e.g., A–B–A–C), enhancing rhythmic predictability and supporting groove and danceability.

### Chordograms

```{r}
"features/wednesday-w-1.json" |> 
  compmus_chroma(norm = "identity") |> 
  compmus_match_pitch_templates(
    key_templates,         # Change to chord_templates if desired
    norm = "identity",      # Try different norms (and match it with what you used in `compmus_chroma`)
    distance = "cosine"   # Try different distance metrics
  ) |>
  ggplot(aes(x = time, y = name, fill = d)) + 
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +               # Change the colours?
  labs(x = "Time (s)", y = "Template", fill = NULL) +
  theme_classic()  
```

> In Track 1, we observe a highly dense and noisy chordogram, with no clear dominant chords over time. This suggests that the harmonic structure is either highly chromatic, constantly shifting, or contains frequent modulations. Such harmonic richness may contribute to expressiveness but may not strongly support predictability or groove — key components of danceability.

### Tempogram

```{r}
"features/wednesday-w-1.json" |>
  compmus_tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

> The tempogram comparison reveals a clear difference in rhythmic consistency between the two tracks. Track 1 exhibits a stable tempo across its duration, with two dominant bands around 95 BPM and 140 BPM. This suggests a layered, polyrhythmic feel that enhances its groove and danceability.

Column{.tabset}
----

### Track 2: Chromagram 

```{r}
"features/wednesday-w-2.json" |>                           # Change the track
  compmus_chroma(norm = "identity") |>                 
  # Change the norm
  ggplot(aes(x = time, y = pc, fill = value)) + 
  geom_raster() +
  scale_y_continuous(
    breaks = 0:11,
    minor_breaks = NULL,
    labels = c(
                "C", "C#|Db", "D", "D#|Eb",
                "E", "F", "F#|Gb", "G",
                "G#|Ab", "A", "A#|Bb", "B"
              )
  ) +
  scale_fill_viridis_c(option = "G") +              
  # Change the colours?
  labs(x = "Time (s)", y = NULL, fill = NULL, main = "track 1 chromagrams") +
  theme_classic()  
```

> Compared to Track 1, this track shows more harmonic variation but less repetition.
It might be more expressive or fluid, but less predictable, which may slightly reduce its danceability.

### Cepstrogram

```{r}
"features/wednesday-w-2.json" |>                           #Change the track
  compmus_mfccs(norm = "identity") |>                  #Change the norm
  ggplot(aes(x = time, y = mfcc, fill = value)) + 
  geom_raster() +
  scale_y_continuous(
    breaks = 0:12,
    minor_breaks = NULL,
  ) +
  scale_fill_viridis_c(guide = "none") +               #Change the colours?
  labs(x = "Time (s)", y = "Coefficient Number", fill = NULL) +
  theme_classic()                                      
```

> In contrast, Track 2 exhibits more activity in the mid-level MFCCs (especially coefficients 4–6), indicating greater timbral variation across time.
While this variation may add sonic interest and subtle rhythmic motion, it could also disrupt the regularity needed for a strong danceable groove.
Overall, the more homogeneous timbre of Track 1 might contribute to stronger perceived danceability, whereas Track 2's textural complexity could either enhance or interfere with it depending on how listeners interpret the changes.

### Chroma-based 

```{r}
"features/wednesday-w-2.json" |>                           # Change the track
  compmus_chroma(norm = "identity") |>                 # Change the norm
  compmus_self_similarity(
    feature = pc,
    distance = "euclidean"                             # Change the distance
  ) |>   
  ggplot(aes(x = xtime, y = ytime, fill = d)) + 
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +               # Change the colours?
  labs(x = "Time (s)", y = NULL, fill = NULL) +
  theme_classic() 
```

> Track 2, in contrast, shows a more varied and diffuse similarity structure. While there are some repeated harmonic segments, the overall pattern is less consistent. This may reflect expressive variation or structural shifts that reduce rhythmic predictability and, in turn, slightly weaken the groove.

### Timbre-based

```{r}
"features/wednesday-w-2.json" |>                           # Change the track
  compmus_mfccs(norm = "identity") |>                  # Change the norm
  compmus_self_similarity(
    feature = mfcc,
    distance = "euclidean"                             # Change the distance
  ) |>   
  ggplot(aes(x = xtime, y = ytime, fill = d)) + 
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +               # Change the colours?
  labs(x = "Time (s)", y = NULL, fill = NULL) +
  theme_classic() 
```

> Track 2, on the other hand, presents a more fragmented and intricate similarity pattern. The lack of strongly defined repeating sections suggests continuous timbral variation, which may offer richness and expressiveness but potentially disrupts the consistency needed for strong perceived danceability.

### Chordograms

```{r}
"features/wednesday-w-2.json" |> 
  compmus_chroma(norm = "identity") |> 
  compmus_match_pitch_templates(
    key_templates,         # Change to chord_templates if desired
    norm = "identity",      # Try different norms (and match it with what you used in `compmus_chroma`)
    distance = "cosine"   # Try different distance metrics
  ) |>
  ggplot(aes(x = time, y = name, fill = d)) + 
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +               # Change the colours?
  labs(x = "Time (s)", y = "Template", fill = NULL) +
  theme_classic()  
```

> By contrast, Track 2 shows much more structured harmonic repetition. We can see vertical bands, especially around the 25s and 75s marks, where certain chords (like C:maj or F:min) dominate across time. This regularity aligns with the self-similarity patterns previously observed and suggests a more repetitive, section-based harmonic plan. This structure may facilitate listener entrainment and thus support danceability.

### Tempogram

```{r}
"features/wednesday-w-2.json" |>
  compmus_tempogram(window_size = 8, hop_size = 1, cyclic = TRUE) |>
  ggplot(aes(x = time, y = bpm, fill = power)) +
  geom_raster() +
  scale_fill_viridis_c(guide = "none") +
  labs(x = "Time (s)", y = "Tempo (BPM)") +
  theme_classic()
```

> Track 2 shows a more singular dominant tempo around 130 BPM, but it undergoes a noticeable disruption near the 75-second mark. This break in rhythmic flow might interfere with its groove and reduce the sense of momentum, potentially contributing to its lower danceability score.

# Conclusion

Finding 1: **Tempo Isn’t Everything**

Even though faster songs seem more energetic, **tempo alone doesn't guarantee danceability**.  
In my analysis, wednesday-w-2 had a higher BPM than roemer-i-2, but was outperformed in danceability.  
> *A fast beat might excite the body, but not necessarily move the feet.*

Finding 2: **Emotion Drives Movement**

The top 5 most danceable tracks had:

- **Higher arousal** (emotional energy)  
- **Higher valence** (positive mood)  
- **Lower instrumentalness** (more vocal presence)

This suggests that emotional intensity and human-like qualities are key to making music feel danceable.

Finding 3: **Structure Matters More Than You Think**

From chroma-based self-similarity and cepstrograms, I found:

- Danceable tracks often show **clear repetition** and **rhythmic regularity**.
- These mid-level structures (groove, loops, call-and-response) are not captured by summary features alone.

By zooming in on my own tracks with chromagrams, MFCCs, self-similarity, and chordograms, I realized:  
*Danceable music is not just heard — it’s felt in your bones.*